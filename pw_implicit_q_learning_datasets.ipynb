{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CumJu-KrCvU"
      },
      "source": [
        "# Practical Work - Implicit Q-Learning\n",
        "\n",
        "<div class=\"alert alert-info\">\n",
        "\n",
        "...\n",
        "\n",
        "<br>\n",
        "\n",
        "...\n",
        "\n",
        "<br>\n",
        "\n",
        "...\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q37atdWHrCvV"
      },
      "source": [
        "### Imports and auxiliary settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUTCq3LfrCvX",
        "outputId": "38227786-11b4-47ae-8164-f2682d803268"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com (185.125.190.36)] [Connecting to security.ubuntu.com (185.125.1\u001b[0m\r                                                                                                    \rHit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [Connected to ppa.launchpadcontent.net (185.125.190.8\u001b[0m\r                                                                                                    \rHit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "40 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Requirement already satisfied: swig in /usr/local/lib/python3.10/dist-packages (4.1.1.post1)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.10/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym) (1.23.5)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym) (0.0.8)\n",
            "Requirement already satisfied: box2d-py==2.3.5 in /usr/local/lib/python3.10/dist-packages (from gym) (2.3.5)\n",
            "Requirement already satisfied: pygame==2.1.0 in /usr/local/lib/python3.10/dist-packages (from gym) (2.1.0)\n",
            "Requirement already satisfied: swig==4.* in /usr/local/lib/python3.10/dist-packages (from gym) (4.1.1.post1)\n",
            "Requirement already satisfied: stable-baselines3[extra] in /usr/local/lib/python3.10/dist-packages (2.2.1)\n",
            "Requirement already satisfied: gymnasium<0.30,>=0.28.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.1.0+cu121)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (1.5.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (3.7.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (4.8.0.76)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.1.0)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.15.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (5.9.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (4.66.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (13.7.0)\n",
            "Requirement already satisfied: shimmy[atari]~=1.3.0 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (1.3.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (9.4.0)\n",
            "Requirement already satisfied: autorom[accept-rom-license]~=0.6.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (0.6.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (8.1.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (2.31.0)\n",
            "Requirement already satisfied: AutoROM.accept-rom-license in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (0.6.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3[extra]) (4.5.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3[extra]) (0.0.4)\n",
            "Requirement already satisfied: ale-py~=0.8.1 in /usr/local/lib/python3.10/dist-packages (from shimmy[atari]~=1.3.0->stable-baselines3[extra]) (0.8.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.60.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.5.1)\n",
            "Requirement already satisfied: protobuf<4.24,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (2.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3[extra]) (2023.3.post1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->stable-baselines3[extra]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->stable-baselines3[extra]) (2.16.1)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from ale-py~=0.8.1->shimmy[atari]~=1.3.0->stable-baselines3[extra]) (6.1.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard>=2.9.1->stable-baselines3[extra]) (1.3.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->stable-baselines3[extra]) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard>=2.9.1->stable-baselines3[extra]) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!apt update\n",
        "!pip install swig\n",
        "!pip install gym gym[box2d]\n",
        "!pip install stable-baselines3[extra]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lBwre4vHrCvg"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "from stable_baselines3 import PPO, DDPG\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38rdHq0uTa4L"
      },
      "source": [
        "# Setup Google Drive mount to store your results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17KBiSj0TbUb",
        "outputId": "bd6e72b1-3b1d-4df5-d043-1e9528a14732"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "use_google_drive = True\n",
        "if use_google_drive:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jM1H78JOz_nh"
      },
      "source": [
        "# Data Collection with Online RL"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function the generate a Dataset\n",
        "def generate_dataset(env, model, num_episodes=100):\n",
        "    dataset = []\n",
        "    for _ in range(num_episodes):\n",
        "        obs = env.reset()\n",
        "        done = False\n",
        "        while not done:\n",
        "            action, _ = model.predict(obs, deterministic=True)\n",
        "            new_obs, reward, done, info = env.step(action)\n",
        "            # Remove the additional dimension\n",
        "            dataset.append((obs[0], action[0], reward[0], new_obs[0], done[0]))\n",
        "            obs = new_obs\n",
        "    return dataset\n",
        "\n",
        "# Function to save dataset to a file\n",
        "def save_dataset(dataset, filename):\n",
        "    with open(filename, 'wb') as f:\n",
        "        pickle.dump(dataset, f)"
      ],
      "metadata": {
        "id": "Po98St2vBeJz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and wrap the environment\n",
        "env_id = 'LunarLanderContinuous-v2'\n",
        "env = make_vec_env(env_id, n_envs=1)"
      ],
      "metadata": {
        "id": "zUDOI38JBmIz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize PPO and DDPG models\n",
        "ppo_model = PPO(\"MlpPolicy\", env, verbose=0)\n",
        "ddpg_model = DDPG(\"MlpPolicy\", env, verbose=0)\n",
        "\n",
        "# Train models and collect datasets\n",
        "for name, model in [('PPO', ppo_model), ('DDPG', ddpg_model)]:\n",
        "    for training_step in tqdm([50000, 100000], desc=f'Training {name}'):\n",
        "        model.learn(total_timesteps=training_step)\n",
        "        tqdm.write(f'\\nGenerating dataset for {name} after {training_step} steps...')\n",
        "        dataset = generate_dataset(env, model, num_episodes=100)\n",
        "        save_dataset(dataset, f'{name}_{training_step}_dataset.pkl')\n",
        "        tqdm.write(f'\\nDataset {name}_{training_step}_dataset.pkl saved.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqO-kJTA6JkK",
        "outputId": "9e2cb093-57dc-41a5-bd6a-da0fa258083f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training PPO:   0%|          | 0/2 [02:56<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generating dataset for PPO after 50000 steps...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training PPO:  50%|█████     | 1/2 [08:01<08:01, 481.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset PPO_50000_dataset.pkl saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training PPO:  50%|█████     | 1/2 [15:21<08:01, 481.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generating dataset for PPO after 100000 steps...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training PPO: 100%|██████████| 2/2 [19:55<00:00, 597.91s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset PPO_100000_dataset.pkl saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training DDPG:   0%|          | 0/2 [18:46<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generating dataset for DDPG after 50000 steps...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training DDPG:  50%|█████     | 1/2 [22:48<22:48, 1368.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset DDPG_50000_dataset.pkl saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training DDPG:  50%|█████     | 1/2 [1:10:52<22:48, 1368.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generating dataset for DDPG after 100000 steps...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training DDPG: 100%|██████████| 2/2 [1:13:51<00:00, 2215.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset DDPG_100000_dataset.pkl saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Random policy dataset generation\n",
        "tqdm.write('\\nGenerating dataset for Random policy...')\n",
        "random_dataset = []\n",
        "for _ in tqdm(range(1000), desc='Random policy steps'):\n",
        "    obs = env.reset()\n",
        "    done = [False]\n",
        "    while not done[0]:\n",
        "        # Sample an action from the action space of the environment\n",
        "        action = [env.action_space.sample()]\n",
        "        # Step through the environment with the action\n",
        "        new_obs, reward, done, _ = env.step(action)\n",
        "        # Append the experience to the dataset\n",
        "        random_dataset.append((obs[0], action[0], reward[0], new_obs[0], done[0]))\n",
        "        obs = new_obs\n",
        "\n",
        "save_dataset(random_dataset, 'Random_1000_dataset.pkl')\n",
        "tqdm.write('Random_1000_dataset.pkl saved.')"
      ],
      "metadata": {
        "id": "on5r3xOCBqcT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64cacf8c-8fdb-42bf-983a-de274ce7f76a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generating dataset for Random policy...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Random policy steps: 100%|██████████| 1000/1000 [01:03<00:00, 15.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random_1000_dataset.pkl saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Close the environments\n",
        "env.close()"
      ],
      "metadata": {
        "id": "LkaZRNq5BrCj"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Move Datasets to Drive-Folder:"
      ],
      "metadata": {
        "id": "6Lu6AWsNOCIl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Move datasets to Google Drive (if using Colab)\n",
        "!cp *.pkl /content/drive/MyDrive/Master-AI/Practical-Work"
      ],
      "metadata": {
        "id": "LOOZTWzzOCsE"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load and check datasets"
      ],
      "metadata": {
        "id": "UZuHSDp-_yri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(filename):\n",
        "    with open(filename, 'rb') as f:\n",
        "        return pickle.load(f)"
      ],
      "metadata": {
        "id": "dziwuNhu_y8i"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of dataset filenames\n",
        "dataset_filenames = ['PPO_50000_dataset.pkl', 'PPO_100000_dataset.pkl',\n",
        "                     'DDPG_50000_dataset.pkl', 'DDPG_100000_dataset.pkl',\n",
        "                     'Random_1000_dataset.pkl']\n",
        "\n",
        "# Load and check each dataset\n",
        "for filename in dataset_filenames:\n",
        "    dataset = load_dataset(filename)\n",
        "\n",
        "    print(f\"Checking dataset: {filename}\")\n",
        "    print(f\"Number of entries: {len(dataset)}\")\n",
        "\n",
        "    # Check the first entry\n",
        "    if len(dataset) > 0:\n",
        "        obs, action, reward, new_obs, done = dataset[0]\n",
        "        print(f\"First entry - obs: {obs.shape}, action: {type(action)}, reward: {type(reward)}, new_obs: {new_obs.shape}, done: {type(done)}\")\n",
        "\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzGonVJf_0di",
        "outputId": "850ade1e-d38c-40a9-b554-6c7c079c74fe"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking dataset: PPO_50000_dataset.pkl\n",
            "Number of entries: 74596\n",
            "First entry - obs: (1, 8), action: <class 'numpy.ndarray'>, reward: <class 'numpy.ndarray'>, new_obs: (1, 8), done: <class 'numpy.ndarray'>\n",
            "\n",
            "\n",
            "Checking dataset: PPO_100000_dataset.pkl\n",
            "Number of entries: 68737\n",
            "First entry - obs: (1, 8), action: <class 'numpy.ndarray'>, reward: <class 'numpy.ndarray'>, new_obs: (1, 8), done: <class 'numpy.ndarray'>\n",
            "\n",
            "\n",
            "Checking dataset: DDPG_50000_dataset.pkl\n",
            "Number of entries: 63571\n",
            "First entry - obs: (1, 8), action: <class 'numpy.ndarray'>, reward: <class 'numpy.ndarray'>, new_obs: (1, 8), done: <class 'numpy.ndarray'>\n",
            "\n",
            "\n",
            "Checking dataset: DDPG_100000_dataset.pkl\n",
            "Number of entries: 53042\n",
            "First entry - obs: (1, 8), action: <class 'numpy.ndarray'>, reward: <class 'numpy.ndarray'>, new_obs: (1, 8), done: <class 'numpy.ndarray'>\n",
            "\n",
            "\n",
            "Checking dataset: Random_1000_dataset.pkl\n",
            "Number of entries: 110110\n",
            "First entry - obs: (8,), action: <class 'numpy.ndarray'>, reward: <class 'numpy.float32'>, new_obs: (8,), done: <class 'numpy.bool_'>\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}